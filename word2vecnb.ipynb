{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('train_final.csv')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"The file 'train_final.csv' was not found.\")\n",
    "\n",
    "\n",
    "assert 'text' in df.columns, \"'text' column is missing in the CSV\"\n",
    "assert 'label' in df.columns, \"'label' column is missing in the CSV\"\n",
    "\n",
    "\n",
    "df['text'].fillna('', inplace=True)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Training set class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"Test set class distribution:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "\n",
    "train_sentences = [word_tokenize(str(sentence)) for sentence in X_train]\n",
    "\n",
    "\n",
    "word2vec_model = Word2Vec(train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "\n",
    "def document_vector(model, doc):\n",
    "    doc = [word for word in word_tokenize(str(doc)) if word in model.wv]\n",
    "    if len(doc) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(model.wv[doc], axis=0)\n",
    "\n",
    "\n",
    "X_train_vectors = np.array([document_vector(word2vec_model, doc) for doc in X_train])\n",
    "X_test_vectors = np.array([document_vector(word2vec_model, doc) for doc in X_test])\n",
    "\n",
    "\n",
    "num_zero_vectors = np.sum([np.all(vec == 0) for vec in X_train_vectors])\n",
    "print(f\"Number of zero vectors in training data: {num_zero_vectors}\")\n",
    "\n",
    "print(f\"Mean of training vectors: {np.mean(X_train_vectors)}\")\n",
    "print(f\"Standard deviation of training vectors: {np.std(X_train_vectors)}\")\n",
    "\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_vectors, y_train)\n",
    "\n",
    "\n",
    "y_pred = nb.predict(X_test_vectors)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "\n",
    "try:\n",
    "    word2vec_model.save(\"word2vec_modeltrialnb.model\")\n",
    "    with open(\"classifier.pkl\", \"wb\") as f:\n",
    "        pickle.dump(nb, f)\n",
    "except Exception as e:\n",
    "    print(f\"Error saving models: {e}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    word2vec_model = Word2Vec.load(\"word2vec_modeltrialnb.model\")\n",
    "    with open(\"classifier.pkl\", \"rb\") as f:\n",
    "        nb = pickle.load(f)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "\n",
    "\n",
    "new_data = [\"Yo! my doc asked me to take some medicines for fever\",\n",
    "            \"I hate him\"]\n",
    "new_data_vectors = np.array([document_vector(word2vec_model, doc) for doc in new_data])\n",
    "new_predictions = nb.predict(new_data_vectors)\n",
    "\n",
    "print(\"Predictions:\", new_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[nltk_data] Downloading package punkt to\n",
    "[nltk_data]     C:\\Users\\green\\AppData\\Roaming\\nltk_data...\n",
    "[nltk_data]   Package punkt is already up-to-date!\n",
    "C:\\Users\\green\\AppData\\Local\\Temp\\ipykernel_17720\\76659239.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
    "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
    "\n",
    "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
    "\n",
    "\n",
    "  df['text'].fillna('', inplace=True)\n",
    "Training set class distribution:\n",
    "label\n",
    "1    2340\n",
    "0     719\n",
    "2     557\n",
    "Name: count, dtype: int64\n",
    "Test set class distribution:\n",
    "label\n",
    "1        574\n",
    "0        193\n",
    "2        137\n",
    "label      1\n",
    "Name: count, dtype: int64\n",
    "Number of zero vectors in training data: 1\n",
    "Mean of training vectors: -0.00650674002119469\n",
    "Standard deviation of training vectors: 0.4803362452375843\n",
    "Accuracy: 0.33480662983425413\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.25      0.81      0.38       193\n",
    "           1       0.77      0.18      0.29       574\n",
    "           2       0.32      0.33      0.32       137\n",
    "       label       0.00      0.00      0.00         1\n",
    "...\n",
    "   macro avg       0.33      0.33      0.25       905\n",
    "weighted avg       0.59      0.33      0.31       905\n",
    "\n",
    "Predictions: ['0' '0']\n",
    "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n",
    "c:\\Users\\green\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "c:\\Users\\green\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "c:\\Users\\green\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "\n",
    "\n",
    "word2vec_model = Word2Vec.load(\"word2vec_modeltrialdt.model\")\n",
    "\n",
    "\n",
    "with open(\"classifier.pkl\", \"rb\") as f:\n",
    "    clf = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def document_vector(model, doc):\n",
    "    doc = [word for word in word_tokenize(str(doc)) if word in model.wv]\n",
    "    if len(doc) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(model.wv[doc], axis=0)\n",
    "\n",
    "\n",
    "new_data = [\n",
    "    \"Yo! my doc asked me to take some medicines for fever\",\n",
    "    \"i hate him for real\"\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "new_data_vectors = np.array([document_vector(word2vec_model, doc) for doc in new_data])\n",
    "\n",
    "\n",
    "new_predictions = clf.predict(new_data_vectors)\n",
    "\n",
    "print(\"Predictions:\", new_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions: ['2' '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    word2vec_model = Word2Vec.load(\"word2vec_modeltrialnb.model\")\n",
    "    with open(\"classifier.pkl\", \"rb\") as f:\n",
    "        nb = pickle.load(f)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "\n",
    "\n",
    "new_data = [\"i hate her\",\n",
    "            \"You almost gave me a heart attack\"]\n",
    "new_data_vectors = np.array([document_vector(word2vec_model, doc) for doc in new_data])\n",
    "new_predictions = nb.predict(new_data_vectors)\n",
    "\n",
    "print(\"Predictions:\", new_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions: ['0' '2']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
